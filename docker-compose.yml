services:
  ingestor:
    build:
      context: .
      dockerfile: ingestor/Dockerfile
    image: cognitive/ingestor:latest
    user: "${COGNITIVE_UID:-1000}:${COGNITIVE_GID:-1000}"
    volumes:
      - ./data/input:/data/input
      - ./outputs:/data/outputs
    # Procesar todos los archivos de /data/input y volcar resultados en /data/outputs/raw
    command: ["/data/input", "--output", "/data/outputs/raw"]

  pipeline:
    build:
      context: .
      dockerfile: pipeline/Dockerfile
    image: cognitive/pipeline:latest
    user: "${COGNITIVE_UID:-1000}:${COGNITIVE_GID:-1000}"
    volumes:
      - ./outputs:/data/outputs
      - ./schemas:/schemas
      - ./outputs:/outputs
    environment:
      - COGNITIVE_ENV=${COGNITIVE_ENV:-dev}
      - COGNITIVE_REDACT=${COGNITIVE_REDACT:-0}
      - COGNITIVE_HASH_SALT=${COGNITIVE_HASH_SALT:-}
      - COGNITIVE_AUDIT_LOG=${COGNITIVE_AUDIT_LOG:-/data/outputs/audit/analysis.jsonl}
      - COGNITIVE_VERBOSE=${COGNITIVE_VERBOSE:-0}
    depends_on:
      ingestor:
        condition: service_completed_successfully
    # Analizar los textos ingeridos y generar insights en JSON
    command: [
      "--input",
      "/data/outputs/raw",
      "--output",
      "/data/outputs/insights/analysis.json"
    ]

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
    image: cognitive/frontend:latest
    user: "${COGNITIVE_UID:-1000}:${COGNITIVE_GID:-1000}"
    ports:
      - "8501:8501"
    volumes:
      - ./outputs:/outputs
    # El comando por defecto se define en el Dockerfile para ejecutar
    # Streamlit. Puede sobreescribirse para usar la interfaz de
    # consola (app.py) o la TUI rich (tui.py).

  gitops:
    build:
      context: .
      dockerfile: gitops/Dockerfile
    image: cognitive/gitops:latest
    profiles:
      - gitops
    environment:
      - GIT_REPO_URL=git@github.com:TU_USUARIO/mi-cerebro-digital.git
      - GIT_BRANCH=main
    volumes:
      - ./outputs:/outputs
